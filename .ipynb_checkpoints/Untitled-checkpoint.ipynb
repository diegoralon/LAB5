{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "experimental-right",
   "metadata": {},
   "source": [
    "# Lab 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-employee",
   "metadata": {},
   "source": [
    "## Cargando y Revisando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "southeast-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "speaking-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Admission_Predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "beginning-latter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "numeric-cheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial No.           0\n",
       "GRE Score            0\n",
       "TOEFL Score          0\n",
       "University Rating    0\n",
       "SOP                  0\n",
       "LOR                  0\n",
       "CGPA                 0\n",
       "Research             0\n",
       "Chance of Admit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-official",
   "metadata": {},
   "source": [
    "Con esta data como viene podemos empezar a trabajar sin embargo tenemos problemas en las variables X que estoy identificando porque usan diferente escala, por lo tanto las debemos de organizar. \n",
    "Las variables que usarare de X serán GRE Score, TOEFL SCORE, cgpa y Research. ya que las demas son situacionales y personales y quiero trabajar con datos empíricos. Por lo tanto tambien nos quedaremos con su SOP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "meaning-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cons'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "chinese-yahoo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
       "       'LOR ', 'CGPA', 'Research', 'Chance of Admit ', 'cons'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "innocent-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['cons','GRE Score' , 'TOEFL Score', 'CGPA','SOP','Research' ]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "divided-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Chance of Admit '].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "duplicate-detail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,) (400, 6)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape,X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-macro",
   "metadata": {},
   "source": [
    "Para hacer que nuestras variables funcionen en la misma escala haremos el proceso de StandarScalet de Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "focused-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "apparent-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "handed-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_S = scaler.fit_transform(X) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-emphasis",
   "metadata": {},
   "source": [
    "Ahora ya tenemos nuestras variables estandarizadas ya podemos cargar nuestras funciones y empezar a hacer pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-booth",
   "metadata": {},
   "source": [
    "## Cargando Funciones con regularizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "partial-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_cost(X, y, theta): \n",
    "    h = X @ theta\n",
    "    return ((y-h)**2).sum() / (2 * len(X)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "standing-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_cost_gradient(X, y, theta, lambda_p = 10): \n",
    "    h = X @ theta\n",
    "    lambda_f = (lambda_p/(2*len(X))) * (theta**2).sum()\n",
    "    return (X.T @ (h-y))/ len(X) + lambda_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "associate-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(\n",
    "X,y,theta_0,linear_cost,linear_cost_gradient,\n",
    "    learning_rate = 0.0001, threshold=0.001, max_iter=10000,lambda_p = 10): \n",
    "    \n",
    "    theta = theta_0\n",
    "    iteration = 0 \n",
    "    costs = []\n",
    "    thetas = []\n",
    "    \n",
    "    while np.linalg.norm(linear_cost_gradient(X,y,theta)) > threshold and iteration < max_iter:\n",
    "        iteration += 1 \n",
    "        theta = theta - (learning_rate * linear_cost_gradient(X,y,theta) + lambda_p * theta)\n",
    "        costs.append(linear_cost(X,y,theta))\n",
    "        thetas.append(theta.copy())\n",
    "        \n",
    "    return theta, costs, thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-prescription",
   "metadata": {},
   "source": [
    "# Polinomio Grado 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-stick",
   "metadata": {},
   "source": [
    "Para empezar con el ejercicio probaremos hacer un polinomio de grado 1 que es con la data como la tenemos actualemente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-regression",
   "metadata": {},
   "source": [
    "### Thetas Iniciales y Separación de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "toxic-solid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1)\n"
     ]
    }
   ],
   "source": [
    "m, n = X.shape\n",
    "theta_0 = np.random.rand(n,1)\n",
    "print(theta_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "banned-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_S)\n",
    "np.random.shuffle(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "phantom-comfort",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 6) (99, 6) (99, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_S[:200]\n",
    "X_cv = X_S[201:300]\n",
    "X_test = X_S[301:400]\n",
    "print(X_train.shape,X_cv.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-structure",
   "metadata": {},
   "source": [
    "Decidi hacer una partición de 50% para el training set y 25% y 25% respectivamente para los test debido a la poca cantidad de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "tropical-liability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,) (99,) (99,)\n"
     ]
    }
   ],
   "source": [
    "y_train = y[:200]\n",
    "y_cv = y[201:300]\n",
    "y_test = y[301:400]\n",
    "print(y_train.shape,y_cv.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "pleased-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, costs, thetas = gradient_descent(X_train,y_train,theta_0,linear_cost,linear_cost_gradient,0.00001,0.001,10000,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "aggressive-happening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.67775226047816\n"
     ]
    }
   ],
   "source": [
    "print(costs[len(costs)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-george",
   "metadata": {},
   "source": [
    "Con un regularizador de Grado 0 Obtenemos este resultado en el costo. Cree que si aumentamos el regulador a  obtenemos un mejor resultado, veremos a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "introductory-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_1, costs_1, thetas_1 = gradient_descent(X_train,y_train,theta_0,linear_cost,linear_cost_gradient,0.00001,0.001,10000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "variable-guide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.6783457395602\n"
     ]
    }
   ],
   "source": [
    "print(costs_1[len(costs_1)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-hanging",
   "metadata": {},
   "source": [
    "Si colocamos un regularizador de dos encontramos que ya tenemos un costo  bajo. pero no lo suficiente para considerar que tiene motivos para hacer las otras pruebas. por lo tanto pasaremos a el polinomio de grado 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-programmer",
   "metadata": {},
   "source": [
    "## Polinomio Grado 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "polish-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CGPA_2'] = df['CGPA'] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-handle",
   "metadata": {},
   "source": [
    "Usaremos de variable el CGPA ya que considero que es una de las variables más importantes del ejercicio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "occupational-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df[['cons','GRE Score' , 'TOEFL Score', 'CGPA','SOP','CGPA_2','Research' ]].to_numpy()\n",
    "y2 = df['Chance of Admit '].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fantastic-desperate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,) (400, 7)\n"
     ]
    }
   ],
   "source": [
    "print(y2.shape,X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "congressional-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_S_2 = scaler.fit_transform(X2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-zambia",
   "metadata": {},
   "source": [
    "### Thetas Iniciales y Separación de data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-garage",
   "metadata": {},
   "source": [
    "m, n = X2.shape\n",
    "theta_0_2 = np.random.rand(n,1)\n",
    "print(theta_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "individual-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_S_2)\n",
    "np.random.shuffle(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "middle-director",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 7) (99, 7) (99, 7)\n"
     ]
    }
   ],
   "source": [
    "X2_train = X_S_2[:200]\n",
    "X2_cv = X_S_2[201:300]\n",
    "X2_test = X_S_2[301:400]\n",
    "print(X2_train.shape,X2_cv.shape,X2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "olive-temple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,) (99,) (99,)\n"
     ]
    }
   ],
   "source": [
    "y2_train = y2[:200]\n",
    "y2_cv = y2[201:300]\n",
    "y2_test = y2[301:400]\n",
    "print(y2_train.shape,y2_cv.shape,y2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "purple-proportion",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta2, costs2, thetas2 = gradient_descent(X2_train,y2_train,theta_0_2,linear_cost,linear_cost_gradient,0.00001,0.001,10000,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "regional-somewhere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.25464306374033\n"
     ]
    }
   ],
   "source": [
    "print(costs2[len(costs2)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "charming-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta2_1, costs2_1, thetas2_1 = gradient_descent(X2_train,y2_train,theta_0_2,linear_cost,linear_cost_gradient,0.00001,0.001,10000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "satisfactory-consequence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.34159061469193\n"
     ]
    }
   ],
   "source": [
    "print(costs2_1[len(costs2_1)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-surgery",
   "metadata": {},
   "source": [
    "En este polinomio logramos reducir un poco el costo al colocar un regularizador de 1. pero todavia no lo suficiente. Probaremos con un polinomio de grado 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-bennett",
   "metadata": {},
   "source": [
    "### Polinomio Grado 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "victorian-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CGPA_3'] = df['CGPA'] ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cordless-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = df[['cons','GRE Score' , 'TOEFL Score', 'CGPA','SOP','CGPA_2','CGPA_3','Research' ]].to_numpy()\n",
    "y3 = df['Chance of Admit '].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "tamil-guinea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,) (400, 8)\n"
     ]
    }
   ],
   "source": [
    "print(y3.shape,X3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "south-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_S_3 = scaler.fit_transform(X3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-flour",
   "metadata": {},
   "source": [
    "### Thetas Iniciales y Separación de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "protected-singapore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1)\n"
     ]
    }
   ],
   "source": [
    "m, n = X3.shape\n",
    "theta_0_3 = np.random.rand(n,1)\n",
    "print(theta_0_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "korean-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(X_S_3)\n",
    "np.random.shuffle(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "phantom-ethics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 8) (99, 8) (99, 8)\n"
     ]
    }
   ],
   "source": [
    "X3_train = X_S_3[:200]\n",
    "X3_cv = X_S_3[201:300]\n",
    "X3_test = X_S_3[301:400]\n",
    "print(X3_train.shape,X3_cv.shape,X3_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "blind-diversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,) (99,) (99,)\n"
     ]
    }
   ],
   "source": [
    "y3_train = y3[:200]\n",
    "y3_cv = y3[201:300]\n",
    "y3_test = y3[301:400]\n",
    "print(y3_train.shape,y3_cv.shape,y3_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "authentic-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta3, costs3, thetas3 = gradient_descent(X3_train,y3_train,theta_0_3,linear_cost,linear_cost_gradient,0.00001,0.001,10000,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "nutritional-sport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.57883336496948\n"
     ]
    }
   ],
   "source": [
    "print(costs3[len(costs3)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "occupational-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta3_1, costs3_1, thetas3_1 = gradient_descent(X3_train,y3_train,theta_0_3,linear_cost,linear_cost_gradient,0.000001,0.001,10000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "armed-qualification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.56989897838429\n"
     ]
    }
   ],
   "source": [
    "print(costs3_1[len(costs3_1)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-billy",
   "metadata": {},
   "source": [
    "Como podemos ver en el siguiente codigo logramos reducir el costo de un polinomio grado 3 a ser mas pequeño que los de polinomio grado 1 y 2. por lo tango nos dentendremos aca y haremos las pruebas de cross validation y test para este polinomio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-impact",
   "metadata": {},
   "source": [
    "### CV polinomio grado 3 con regularizador de 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-perth",
   "metadata": {},
   "source": [
    "# Lo entregare así que tengo duda de porque no me deja multiplicarlos. No entiendo el resultado que me da las thetas que me da un array mas grande del que necesito. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-connection",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
